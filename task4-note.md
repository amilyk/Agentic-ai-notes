# Task4学习笔记（Agent开发流程评估）

> 本笔记是基于Datawhale开源课程[Agentic‑AI](https://github.com/datawhalechina/agentic-ai) 的@kangxun 个人学习笔记

### 网页搜索组件评估实践

**实践场景**：调研某主题的行业进展，LLM调用搜索工具API，返回的链接中是优选域名的比例 </br>
**实践结论**
1. prompt里需加上“`返回的结果必须包含论文或网页链接，链接内容要以https开头，不要pdf链接，相同论文链接要去重`”。否则可能会导致返回无链接，无法计算重合度。</br>
2. 自定义主题中，生物、医药、计算机、量子领域用相同优选域名，论文多发于arxiv，通过率都很高。但社科、金融领域（排除量化外），不能运用上述相同的优选域名，通过率会很低。每个领域参考文献有自己的特色，扩展域名的时候要根据领域。</br>

## 1.Agent 系统开发流程评估

### 1️⃣ 快速原型

* ​**目标**​：快速搭建一个可运行的系统。
* ​**方式**​：手动检查最终输出，确保基本功能可用。

### 2️⃣ 初步评估

* ​**数据规模**​：使用小型数据集（≈10‑20 条样例）。
* ​**评估维度**​：计算整体性能指标（端到端评估）。
* ​**评估手段**​：
  * ​**客观评估**​：通过代码自动检查。
  * ​**生成类评估**​：使用 LLM 对结果进行评价。
* ​**案例**​：
  * **发票处理流程** → 代码对比输出的到期日与实际到期日是否一致。

### 3️⃣ 错误分析

* ​**数据规模**​：使用稍大数据集（≈10‑100 条）。
* ​**目标**​：量化每个组件的出错概率，定位错误最多的环节。
* ​**案例**​：
  * **发票处理流程**
    * PDF 转文本
    * LLM 文本提取到期日
  * ​**发现**​：约 45% 的错误是 LLM 抽取了错误的日期 → 需要优化 LLM 提示词。

### 4️⃣ 高效调优

* ​**思路**​：组件级评估，单独调用并优化每个组件的输出。
* ​**案例**​：
  * ​**网页搜索组件评估**​：搜索结果与标准网页（由人类专家定义）的匹配概率。

#### 组件优化方法


| 类型          | 优化手段 |
|---------------|----------|
| **非 LLM 组件** | - **调整参数 / 超参数**：</br> • **网页搜索** – 调整返回结果数量、日期范围</br> • **RAG 检索** – 更改相似度阈值、文本分块大小等</br> • **人物检测** – 调整检测阈值</br>- **替换组件**：使用不同的 RAG 搜索引擎或 Web 搜索 API |
| **LLM 组件**   | - **改进提示词**：明确指令 + 少样本示例</br>- **尝试不同 LLM**</br>- **任务分解**：拆成多步骤 + 反思</br>- **微调模型** |


#### LLM 组件直觉培养

1. ​**多模型实践**​：建议至少掌握 3‑5 种主力模型，并在一个月内尝试 10 种以上模型，了解各自擅长的领域。
2. ​**阅读提示词**​：大量阅读从业者、专家或开源框架中的优秀提示词。
3. ​**实战追踪**​：在 Agent 工作流中尝试不同模型，查看 **Traces** 与组件/端到端评估，观察它们在特定任务中的 **性能、价格、速度** 权衡。

---

## 2. Agent 流程的成本与延迟优化

​**前期**​：侧重高质量输出。
​**后期**​：用户量上升后，重点优化 **延迟** 与 ​**成本**​。

### 1️⃣ 时间线分析

* ​**做法**​：统计每个步骤的耗时。
* ​**优化手段**​：并行化处理、替换更快的 LLM。

### 2️⃣ 成本测试

* ​**计费方式**​：
  * ​**LLM**​：按输入/输出 Token 长度计费。
  * ​**API**​：按调用次数计费。
  * ​**计算/服务**​：依据服务器容量、服务费等计费。

### 📌 小结

*通过 **快速原型 → 初步评估 → 错误分析 → 高效调优** ，不断量化、定位并优化每个组件，配合成本与延迟的持续监控，可实现高质量且经济高效的 Agent 系统。

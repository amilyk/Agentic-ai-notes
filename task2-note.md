# Task2学习笔记（反思设计模式）

> 本笔记是基于Datawhale开源课程[Agentic‑AI](https://github.com/datawhalechina/agentic-ai) 的@kangxun 学习笔记

### 实验结论

在 **初稿阶段** 选择生成速度快且生成效果不错的模型，过于追求生成速度虽然能提升效率，但这些模型的能力相对较弱，导致 ​**反思阶段**​（使用强模型）无法给出高质量的修改建议，也难以产生更优的版本更新。

#### 1.SQL 生成任务

​**任务描述**​：查询销量最高的颜色及其销量总和。

| 模型（+GPT4.1 V2）                                            | V2 结果表现 | 初稿问题                                                                              |
| ------------------------------------------------- | ---------- | --------------------------------------------------------------------------------------- |
| **GPT‑4.1**                         | 正确     | 初稿就发现 `action = sales` 中 `delta < 0`，在计算销量时加入了 `ABS()` 取绝对值                                                                                    |
| **DeepSeek‑Chat**                        | 错误     |初稿 `WHERE` 条件限制了 `delta > 0`，导致查询结果为空，V2版本结果为空                              |
| ​**GPT‑4o**​、**GPT‑4.1‑mini** | 错误     | 初稿只能返回 `color`，未计算销量，V2版本为负值           


结论：初稿使用GPT‑4.1，V2使用GPT-4.1反思

#### 2.图表生成任务

​**任务描述**​：基于本地 CSV 数据绘制 **2024‑2025 年咖啡销量** 的折线图。

| 模型 （+GPT4.1 V2）                                            | 初稿表现                                 | 备注                     |
| -------------------------------------------------- | ------------------------------------------ | -------------------------- |
| **GPT‑4.1‑mini**                         | 快速生成（无年代标签，且同类咖啡未聚合） | 速度快，但可读性不足     |
| ​**GPT‑4o**​、**GPT‑3.5‑turbo** | ​**报错**​，无法生成图表         | 生成阶段即失败           |
| **DeepSeek‑Chat**                         | 与 **GPT‑4.1** 效果相当           | 初稿能得到可读性强的图表     |
| ​**GPT‑4.1**​                 | 提升可读性，加入标签、聚合同类咖啡       | 初稿能得到可读性强的图表 |

结论：初稿使用GPT‑4.1‑mini（速度快），V2使用GPT-4.1反思

---

## 1️⃣ AI反思流程

1. **人类提出问题** → LLM 生成 **初稿 V1**
2. LLM 根据 **​（问题 + V1 + V1 的执行结果）​**‍ 给出 ​**修改意见**​，并生成 **新版本 V2**

---

## 2️⃣带反思工程流中LLM的选择

| 阶段                   | 推荐模型                     | 说明                                       |
| ------------------------ | ------------------------------ | -------------------------------------------- |
| **直接生成初稿** | GPT‑4 / GPT‑5（通用 base） | 生成速度快，适合快速产出草稿               |
| **反思阶段**     | 推理能力强的思考模型         | 接收代码、图表、对话历史等，进行审核与优化 |

---

## 3️⃣ 反思模式的价值

* 在 **多模型多任务** 场景下，**反思模式**显著优于 ​**0‑shot 直接生成**​（未反思）模式。
* 虽然会多调用一次 LLM，导致一定的 ​**耗时增加​**​，但相对提升的性能而言，成本仍然较低。

---

## 4️⃣ 反思 Prompt 的核心要素

1. **明确改进动作**
   * 比如：`请审查`、`请验证`、`请审核电子邮件初稿` 等。
2. **明确检查评估标准**
   * 比如：在邮件任务中，评估标准可以是 ‍**​“语气专业”​**‍ 与 ‍**​“事实准确”​**‍。

---

## 5️⃣ 反思模式案例 —— 咖啡销售数据的图表可视化

| 步骤                    | 内容                                                                                                                                                                                     |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **LLM 初稿 (V1)** | 根据 `sales.data` 生成代码并执行，得到 ​**堆叠条形图**​。
问题：堆叠方式导致 2024 与 2025 年不同咖啡品类的销售对比不清晰。                                                   |
| **LLM V2**        | 将 **V1 的代码 + 图表** 输入多模态大模型，设定角色为 ‍**​“专家数据分析师”​**‍。
依据 **可读性、完整性、清晰度** 生成改进后的代码和更易读的图表（如并列条形图）。 |

### 反思 Prompt 示例

```
{V1 代码} {plot.png} {对话历史记录}
步骤 1：评估所附图表的可读性、清晰度和完整性。  
步骤 2：编写新代码来实现您的改进。
```

---

## 6️⃣ 反思阶段的评估

| 评估类型           | 说明                     | 任务类型                                                |
| -------------------- | -------------------------- | ------------------------------------------------------- |
| **客观评估** | 有明确正确答案           | 数据查询任务的 **准确率** 与 **查询效率** |
| **主观评估** | 无唯一答案，需要人工打分 | 图表可读性（如标题清晰度、图表类型匹配度等）          |

* 比如数据库任务，可通过多次query比较 **有无反思** 的表现差异

---

## 7️⃣ 引入外部反馈的优势

* ​**网络搜索**​：核对论文中术语的表达准确度，增加网络搜索比 LLM 直接检查更可靠，能有效降低幻觉。
* ​**代码更新任务**​：LLM 初稿代码执行后的 **output** 与 **error** 更客观，结合这些信息进行反思，比仅凭初稿评审意见的反思更有价值。

---

### 📌 小结

* ​**AI 反思流程**​：先生成 → 再审查 → 再改进，形成闭环。
* ​**Prompt 设计**​：明确动作 + 明确评估标准，是提升反思效果的关键。
* ​**模型选型**​：通用模型负责快速产稿，思考模型负责深度审查与优化。
* ​**外部反馈**​（搜索、执行日志）能够显著提升质量，尤其在防止幻觉方面效果突出。

